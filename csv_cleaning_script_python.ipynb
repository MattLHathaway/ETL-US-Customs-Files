{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCRIPT FOR CLEANING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Packages and creating a Dataframe to use as a list of acceptable identifier column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Create list to audit PKs with\n",
    "# This script was applied to these files already to remove duplicates and filter down to only identifier row\n",
    "file_path = r'/Users/matthew/Desktop/pk_list_csv/'\n",
    "all_pk_files = glob.glob(os.path.join(file_path, \"*.csv\"))\n",
    "df1 = pd.concat((pd.read_csv(f) for f in all_pk_files), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Dataframe for our Table by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all CSVs together using glob and pd.concat\n",
    "directory_pk = r'/Users/matthew/Desktop/pk_list_csv'\n",
    "directory_18 = r'/Users/matthew/Desktop/SkillStorm/python_install_test/Project_1/bronze_layer/2018'\n",
    "directory_19 = r'/Users/matthew/Desktop/SkillStorm/python_install_test/Project_1/bronze_layer/2019'\n",
    "directory_20 = r'/Users/matthew/Desktop/SkillStorm/python_install_test/Project_1/bronze_layer/2020'\n",
    "folder = 'cargodesc'\n",
    "path = os.path.join(directory_18, folder)\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "all_pk_files = glob.glob(os.path.join(directory_pk, \"*.csv\"))\n",
    "df = pd.concat((pd.read_csv(f) for f in all_pk_files), ignore_index=True)\n",
    "\n",
    "# Create DF for table\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the Dataframe into Table Columns useful to my Use Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the DF into only the columns I want to keep\n",
    "df = df[['identifier', 'container_number', 'piece_count', 'description_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Duplicates From the Identifier Column to ensure Data Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Duplicate Rows based on identifier column\n",
    "df = df.drop_duplicates(\n",
    "    subset = ['identifier'],\n",
    "    keep = 'first').reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Rows that do not match our Audit List to Ensure Primary Key Stability in our Relational Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows that don't match Primary Key from Headers Table\n",
    "df = df[df.identifier.isin(df1['identifier'])]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new CSV with the changes applied for the Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'/Users/matthew/Desktop/final_silver_layer/cargodesc/cargodesc_2018.csv'\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging our changes into a TXT file located in the Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging the changes made in a text file\n",
    "from datetime import datetime\n",
    "\n",
    "def log_changes(log_file, edited_file_name, string_message):\n",
    "    f = open(log_file, 'a')\n",
    "    f.write(\"{0} -- {1}\\n\".format(datetime.now().strftime(\"%Y-%m-%d %H:%M\"), string_message + f'File Changed: {edited_file_name} UN: Matthew Hathaway'))\n",
    "    f.close()\n",
    "\n",
    "log_file = r'/Users/matthew/Desktop/final_silver_layer/log.txt'\n",
    "edited_file_name = 'cargodesc_2018.csv'\n",
    "\n",
    "log_changes(log_file, edited_file_name, 'Took out duplicates from the identifier column')\n",
    "log_changes(log_file, edited_file_name, 'Removed unecessary columns for our Use Case')\n",
    "log_changes(log_file, edited_file_name, 'Created new CSV file in Silver Layer only containing newly transformed data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
